---
type: slides
---

# Как приготовить модель

---

# Модель Байеса

Наивный Байесовский классификатор использует модель Байеса для предсказания вероятностей. Если проще, он вычисляет, насколько вероятна принадлежность текста к определённому классу при наличии в нём конкретных слов.
Для работы с моделью используем библиотеку scikit-learn, из которой мы уже брали преобразователь текстов. 
Библиотека предлагает несколько вариантов моделей Байеса:
- Гауссовская модель – для нормально распределённых признаков
- Бинарная модель – для признаков с двумя значениями (наличие/отсутствие)
- Мультиномиальная модель – для признаков с несколькими значениями. 
- Комплементарная модель – также подходит для признаков с несколькими значениями, но учитывает возможную несбалансированность выборки. Мы будем использовать именно её. 
Notes: 
Подробнее о теореме Байеса и работе алгоритма: 
https://ru.wikipedia.org/wiki/Наивный_байесовский_классификатор

---

# Готовим модель
Для того, чтобы использовать модель, надо импортировать её из библиотеки scikit-learn и внедрить в код, создав нашу собственную модель.
Помните, как мы выделяли зависимую и независимую переменные из таблицы с отзывами? Теперь они как раз нам пригодятся. 
Зададим колонку 'review' как X – переменная для обучения, а зависимую 'rating' как Y – целевую переменную.

```python
# импортируем комплементарную модель
from sklearn.naive_bayes import ComplementNB
X = vectorizer.fit_transform(hotels_df['review'].values)
y = hotels_df['rating'].values
model = ComplementNB()
```

Notes: Для модели необходимы переменные количественного типа, поэтому сами отзывы мы приводим к числовому виду с помощью векторизатора, а оценки оставляем как есть, так как они уже представлены в числовом виде.

---

# Обучаем и тестируем модель

Для обучения модели используется команда fit, которой передаются все тренировочные данные (наши X и Y). Модель обработает их и выведет для себя закономерности. Для проверки качества работы модели используются тестовые данные – те, которых не было в тренировочном корпусе и для которых мы знаем правильные ответы. Чтобы поделить выборку на тестовую и обучающую в sklearn есть специальная функция train_test_split.
```python
from sklearn.model_selection import train_test_split
# поделим выборку на тестовую и обучающую:
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)
# обучим модель
model.fit(X, Y)
# получим предсказанные значения
predicted = model.predict(X_test)
```
Чтобы понять, насколько хорошо наша модель предсказала значения, воспользуемся метрикой accuracy (точность), которая вычисляет долю правильных ответов:

```python
from sklearn.metrics import accuracy_score
accuracy_score(y_test, predicted)
```
```out
0.6185475521372578
```
Notes: 
- Подробнее об аргументах функции train_test_split см. 
https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html
- Чем выше уровень точности, тем лучше, однако, если точность равна 1, это означает, что модель переобучилась - она не вывела обобщающую закономерность и потеряла предсказательную способность.
---

# Перейдем к заданиям