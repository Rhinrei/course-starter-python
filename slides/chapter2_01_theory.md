---
type: slides
---

# Загрузка и подготовка данных

---

# Корпус текстов как объект pandas

При анализе больших корпусов текстов и их характеристик данные удобно обрабатывать как объект pandas – библиотеки для анализа данных языка Python. 
С помощью pandas можно обрабатывать самые разные типы файлов, но удобнее всего работать с файлами csv.

```python
# импортируем библиотеку
import pandas as pd
# убираем ограничение библиотеки и выводим все колонки
pd.set_option('display.expand_frame_repr', False)
# загружаем набор данных с текстами отзывов об отелях
hotels_csv = pd.read_csv('reviews.csv')
# преобразуем наш полученный набор данных в DataFrame - структуру данных библиотеки pandas
hotels_df = pd.DataFrame(hotels_csv)
```

Notes: - Pandas сокращается как pd для удобства.
- С # начинаются строки-комментарии. Они не распознаются как код, поэтому удобны, чтобы передать информацию в свободной форме другим людям или будущему себе.
- pd.set_option('display.expand_frame_repr', False) - технический момент, если не понимаете как работает, можно на нем не останавливаться

---

# Корпус текстов как объект pandas

```python
# выведем первые пять элементов датафрейма для просмотра с помощью функции head()
print(hotels_df.head())
```
Результат:
<img src="/hotels_head_output.png"/>
При просмотре данных из файла csv pandas преобразует их в понятную таблицу, к которой можно обращаться по именам колонок и порядковым номерам строк (начиная с 0).
Как можно видеть, сами отзывы содержатся в колонке review, а оценка отзыва – в колонке rating.
Отзывы оцениваются от 1 до 5. Будем считать, что оценки 1 и 2 означают негативные отзывы, 3 – нейтральные, а 4 и 5 – положительные.
В будущем мы будем работать только с этими двумя колонками.

Notes: По умолчанию функция head() выводит первые пять строк. Но вы можете вывести меньше или больше строк, подставив необходимое число, например, head(3) выведет три строки.
Обратите внимание, что нумерация строк начинается с 0.

---

# Готовим данные для модели: убираем пустые значения

Посмотрим на другие примеры с помощью команды tail, показывающую последние строки таблицы. 
<img src="/hotels_tail_output.png"/>
Можно видеть, что в некоторых строках нет самих отзывов – они обозначаются как NaN. В pandas есть специальная функция dropna, которая удаляет все строки или столбцы с пустыми ячейками.
```python
hotels_df = hotels_df.dropna(axis=0)
print(hotels_df.tail())
```
<img src="/hotels_tail_dropna_output.png"/>
Notes:

---

# Готовим данные для модели: выбираем нужные столбцы

Функции head и tail позволяют выбирать строки из начала и конца списка. Но что, если нам нужно выбрать строки из середины данных или столбцы?
Для этого можно использовать структуру iloc у датафрейма. 

```python
# используйте iloc для обращения по индексу. Следующий код выведет на печать строки 5-6 и 
# колонки 2-3. Почему так? Интервал не включает в себя последнее значение: строка 7 и 
# столбец 4 не выходят на печать. И не забудьте, что нумерация начинается с 0.
print(hotels_df.iloc[5:7, 2:4])
```
```out
                      quote  rating
5  Место, где живет история       5
6          Отель с историей       5
```
Notes:

---

# Готовим данные для модели: зависимая и независимая переменные

Чтобы определить тональность отзыва будем использовать его оценку как показатель этой тональности. Тогда данные из колонки rating будут для нас целевыми (иначе говоря, зависимой переменной), именно их модель будет учиться определять.
А вот колонка review будет независимой переменной – модель будет смотреть, как она соответствует той или иной оценке. То есть по некоторым характеристикам текстов в review мы сможем предсказать, какую оценку имеет наш отзыв.
```python
#  определим независимую переменную как переменную review
review = hotels_df['review'].values
# вынесем целевую переменную в переменную Y 
Y = hotels_df['rating'].values
```

Notes:
---

# Из текста в цифры – подсчёт частоты

Мы работаем со множеством текстов, но компьютерные модели не могут читать и воспринимать смысл текста так, как это делает человек. Текст нужно перевести в понятный для модели «язык» численных характеристик.
Для этого используем библиотеку scikit-learn, которая предлагает несколько вариантов трансформации текста в его численные характеристики.
Метрика, которая чаще всего используется в задачах анализа текста, называется TfIdf. Она сочетает простоту и эффективность.

```python
# импортируем библиотеку
from sklearn.feature_extraction.text import TfidfVectorizer
# сделаем корпус предложений для примера
corpus = [
     'Это первый документ.',
     'Этот документ - второй документ.',
     'Вот это третий.',
     'Первый ли это документ?',
 ]
```
Notes: Больше информации см. на 
https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html

---

# Из текста в цифры – подсчёт частоты

```python
vectorizer = TfidfVectorizer()
# передадим наш корпус векторизатору, который выделит характеристики (слова) 
и составит из них матрицу
X = vectorizer.fit_transform(corpus)

# посмотрим, что получилось: распечатаем все полученные с помощью векторизатора слова...
print(vectorizer.get_feature_names())
# ... и размер матрицы, где первое значение - количество документов (предложений) в корпусе, 
второе - количество характеристик (слов) 
print(X.shape)
```

```out
['вот', 'второй', 'документ', 'ли', 'первый', 'третий', 'это', 'этот']
(4, 8)
```

Эта метрика вычисляет «важность» слова в зависимости от его частоты  и  общего числа слов в тексте, а также частоты слова во всех текстах. 
Чем чаще слово встречается во всём корпусе, тем оно менее «важно» – как, например, служебные слова. И, наоборот, специфичные для конкретного текста слова считаются более «важными».

---

# Let's practice!

Notes: Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam tristique
libero at est congue, sed vestibulum tortor laoreet. Aenean egestas massa non
commodo consequat. Curabitur faucibus, sapien vitae euismod imperdiet, arcu erat
semper urna, in accumsan sapien dui ac mi. Pellentesque felis lorem, semper nec
velit nec, consectetur placerat enim.
